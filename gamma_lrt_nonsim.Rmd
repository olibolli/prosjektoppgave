---
title: "gamma_lrt_nonsim"
author: "Olai Gaarn Skogen"
date: "2025-04-01"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(VGAM) # plgamma, distribution functions of log-gamma
library(distr) # igamma, to calculate MLE of alpha
library(cubature) # adaptIntegrate, to calculate multidimensional integrals
```

```{r}
?uniroot
```


We first take the case where n = 1, because then we have the distribution function for $\operatorname{log}(X)$ if $X \sim \text{Gamma}(\alpha, \beta)$.

We can go from 
1. $T(X) = \operatorname{log}(X)$ sufficient statistic to
2. $l(X; \alpha) = \alpha \sum_i{T(X_i)} - n \operatorname{log}(\alpha)$ likelihood to
3. $\hat{\alpha} = \frac{n}{\sum_i{T(X_i)}}$ mle to
4. $\Lambda(X) = \exp\{l(X; \hat{\alpha}) - l(X; \alpha_0) \}$ likelihood ratio

If we can find the critical value numerically, then we can also find the power numerically.

Pretty sure we did something similar in StatInf.

# Everything is for the Gamma function - test for shape parameter


```{r}
# find critical values for c
log_likelihood <- function(t, alpha){
  # TODO : For more than one value t
  (alpha-1) * t -  lgamma(alpha)
}

likelihood_ratio_calc <- function(t, alpha_0){
  alpha_hat = igamma(mean(t))
  log_lr =  log_likelihood(t, alpha_hat) - log_likelihood(t, alpha_0)
  log_lr
}

## finding t_dual, i.e. the value of t that gives the same LR value
find_t_dual <- function(t, alpha_0){
  # Assuming t_dual is higher than t
  # TODO : finding a way to make it go both ways
  lr <- likelihood_ratio_calc(t, alpha_0)
  
  modified_func <- function(t) {likelihood_ratio_calc(t, alpha_0) - lr}
  
  t_dual <- uniroot(modified_func, lower = t + 1e-4, upper = 10, extendInt = "no")$root
  t_dual
}

t = log(1)
log_likelihood(t, 2)
likelihood_ratio_calc(t, 2)

find_t_dual(t, 2)

## actually finding the critical value c

find_extremity_prob <- function(t, alpha_0){
  t_dual <- find_t_dual(t, alpha_0)
  1 - plgamma(t_dual, shape = alpha_0) + plgamma(t, shape = alpha_0)
}

find_extremity_prob(t, 2)

find_critcal_vals <- function(significance_level, alpha_0){
  modified_func <- function(t) {find_extremity_prob(t, alpha_0) - significance_level}
  
  print(modified_func(-5))
  print(modified_func(0))
  
  # NOTE : It is hard to find a good upper boundary for where to start the search for t1. 
  ## This is because find_t_dual requires that you propose a value lower than corresponding t2, (ie lower than the t maximizing the LR). 
  ## At the same time it must be large enough that it contains the t1 that gives the wanted significance level
  ## We have choosen upper = 0 for significance level = 0.05
  
  t1 <- uniroot(modified_func, lower = -5, upper = 0)$root
  t2 <- find_t_dual(t1, alpha_0)
  
  c1 = likelihood_ratio_calc(t1, alpha_0)
  c2 = likelihood_ratio_calc(t2, alpha_0)
  
  c(t1, t2, c1, c2)
}

crit_vals = find_critcal_vals(0.05, 2)
crit_vals
# find critical values t1 and t2


# find power
find_power <- function(alpha_true, t1, t2){
  1 - plgamma(t2, shape = alpha_true) + plgamma(t1, shape = alpha_true)
}

```

```{r}
start = 1.9
end = 2.1
n = 41

alpha_values <- seq(start, end, length.out = n)

pwr_values <- sapply(alpha_values, find_power, t1 = crit_vals[1], t2 = crit_vals[2])

plot(alpha_values, pwr_values)
```
# Trying to calculate CDF for sum(T)

n = 2
$P(\bar{T} < t) = \int_{-\infty}^{t} \int_{-\infty}^{\infty} f_{T_1}(u) f_{T_2}(v-u) du \ dv $

```{r}
# Define the integrand
integrand <- function(x, alpha, beta = 1) {
  u <- x[1]
  v <- x[2]
  dlgamma(u, shape = alpha, scale = 1/beta) * dlgamma(v-u, shape = alpha, scale = 1/beta)
}

# Parameters
alpha <- 2
t <- 0

# Perform the double integration
result <- adaptIntegrate(integrand, lowerLimit = c(-Inf, -Inf), upperLimit = c(t, Inf), alpha = alpha)

cat("Integral result:", result$integral, "\nError estimate:", result$error, "\n")
```

## Lots of WIP and intresting findings by running this code block

```{r}
log_gamma_integrand<-function(x, alpha, beta = 1){
  product <- 1
  term <- 0
  n <- length(x)
  # This loop might be a bit inefficient
  for (i in 1:n) {
    term <- dlgamma(x[i] - sum(x[0:(i-1)]), shape = alpha, scale = 1/beta)
    product <- product * term
  }
  product
}

plgamma_mult<-function(t, integrand, n, alpha, beta = 1){
  lower = rep(-Inf, n)
  upper = rep(Inf, n)
  upper[1] = t*n
  
  pT <- adaptIntegrate(integrand, lowerLimit = lower, upperLimit = upper, alpha = alpha, beta = beta)
}

# Parameters
alpha <- 2
t <- -0.5
n <- 2

result2 <- plgamma_mult(t, log_gamma_integrand, n, alpha)

result2
```

## Trying to get WIP results for the power function for n = 3

```{r}
find_extremity_prob_mult <- function(t, alpha_0, n){
  t_dual <- find_t_dual(t, alpha_0)
  print(t_dual)
  1 - plgamma_mult(t_dual, log_gamma_integrand, n = n, alpha = alpha_0) + plgamma_mult(t, log_gamma_integrand, n = n, alpha = alpha_0)
}

find_extremity_prob_mult(t, 2, 2)

find_critcal_vals_mult <- function(significance_level, alpha_0, n){
  modified_func <- function(t) {find_extremity_prob_mult(t, alpha_0, n) - significance_level}
  
  print(modified_func(-5))
  print(modified_func(0))
  
  # NOTE : It is hard to find a good upper boundary for where to start the search for t1. 
  ## This is because find_t_dual requires that you propose a value lower than corresponding t2, (ie lower than the t maximizing the LR). 
  ## At the same time it must be large enough that it contains the t1 that gives the wanted significance level
  ## We have choosen upper = 0 for significance level = 0.05
  
  t1 <- sum(uniroot(modified_func, lower = -5, upper = 0)$root)
  t2 <- sum(find_t_dual(t1, alpha_0))
  
  c1 = likelihood_ratio_calc(t1, alpha_0)
  c2 = likelihood_ratio_calc(t2, alpha_0)
  
  c(t1, t2, c1, c2)
}

crit_vals = find_critcal_vals_mult(0.05, 2, 2)
crit_vals
# find critical values t1 and t2


# find power
find_power_mult <- function(alpha_true, t1, t2){
  1 - plgamma_mult(t2, shape = alpha_true) + plgamma_mult(t1, shape = alpha_true)
}
```









