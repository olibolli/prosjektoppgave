---
title: "power_calc_fischer"
author: "Olai Gaarn Skogen"
date: "2024-09-22"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(ggplot2)
library(reshape2)
library(tidyverse)
library(plotly)
library(GGally)
library(ggtext)
library(glue)
```

## Model for binomial

```{r}
dmodel <- function(x, c, n_1, n_2){
  dhyper(x, n_1, n_2, c)
}

pmodel <- function(x, c, n_1 = 10, n_2 = 10){
  phyper(x, n_1, n_2, c)
}

sample_space <- function(c){
  0:c
}

expected_val_model  <- function(c, n_1, n_2){
  c*n_1 /(n_1 + n_2)
}

```


## Methods for computing p_value
```{r}
p_val_a <- function(x, c, n_1, n_2){
  pr_tail_l = pmodel(x, c, n_1, n_2)
  ## Use 1 - tail prob but add point prob
  pr_tail_r = 1 - pr_tail_l + dmodel(x, c, n_1, n_2)
  
  p_val = 2 * min(pr_tail_l, pr_tail_r, 1/2)
  p_val
}

p_val_a(6, 10, 7, 10)
```

```{r}
p_val_b <- function(x, c, n_1, n_2, multi_modal = TRUE){
  W_x = dmodel(x, c, n_1, n_2)
  
  S = sample_space(c)
  p_val = 0
  
  if (multi_modal){
    # If multimodal makes this a bad for this p-method
    for(y in S){
      W_y = dmodel(y, c, n_1, n_2)
      if(W_y > W_x){
      }
      else{
        p_y = W_y
        p_val = p_val + p_y
      }
    }
  }
  else{
    #WIP of effectivised computation
  }
  
  p_val
}

p_val_b(3, 10, 6, 20, TRUE)
```

```{r}
# Assuming point mass function
p_val_c <- function(x, c, n_1, n_2){
  p_tail_l = pmodel(x, c, n_1, n_2)
  p_tail_r = 1 - p_tail_l + dmodel(x, c, n_1, n_2)
  epsilon = 1e-8
  if (p_tail_l < p_tail_r + epsilon){
    # Add the maximum right tail that is smaller than left tail
    ## Start with 0 tail and add one point mass at a time until it grow bigger than left tail
    r_tail_max_smaller = 0
    y = c
    sugg = r_tail_max_smaller
    while(sugg < p_tail_l + epsilon){
      r_tail_max_smaller = sugg # Accept suggestion
      r_add = dmodel(y, c, n_1, n_2) # Calculate new point mass to be added
      sugg = sugg + r_add # Propose new suggestion
      y = y - 1 # Take one lower y-value
    }
    p_val = p_tail_l +  r_tail_max_smaller
  }
  else{
    # Do the same thing but find maximum smaller left tail instead of right
    l_tail_max_smaller = 0
    y = 0
    sugg = l_tail_max_smaller
    while(sugg < p_tail_r + epsilon){
      l_tail_max_smaller = sugg # Accept suggestion
      l_add = dmodel(y, c, n_1, n_2) # Calculate new point mass to be added
      sugg = sugg + l_add # Propose new suggestion
      y = y + 1 # Take one higher y-value
    }
    p_val = p_tail_r +  l_tail_max_smaller
  }
  if(p_val > 1){ # If the distrbution is symmetric it will count the central event twice.
    return(1)
  }
  p_val
}

p_val_c(7, 10, 20, 14)
```

```{r}
# Modifications of methods for optimized power calc
p_val_c_power <- function(x, c, n_1, n_2, a = 0.05){
  # This function will determine if the given experiment and data resulted in a rejection or not wrt to the hypothesis test/significance level
  p_tail_l = pmodel(x, c, n_1, n_2)
  p_tail_r = 1- p_tail_l + dmodel(x, c, n_1, n_2)
  epsilon = 1e-8
  if (p_tail_l < p_tail_r + epsilon){
    if(p_tail_l > a){
      # If the lowest tail value is higher than the significance level the null hypothesis is not rejected
      return(1)
    }
    if(2*p_tail_l < a){
      # If the highest tail value you add to the p_value is lower than half the null hypthesis is rejected
      return(0)
    }
    # Add the maximum right tail that is smaller than left tail
    ## Start with 0 tail and add one point mass at a time until it grow bigger than left tail
    r_tail_max_smaller = 0
    y = c
    sugg = r_tail_max_smaller
    while(sugg < p_tail_l + epsilon){
      r_tail_max_smaller = sugg # Accept suggestion
      r_add = dmodel(y, c, n_1, n_2) # Calculate new point mass to be added
      sugg = sugg + r_add # Propose new suggestion
      y = y - 1 # Take one lower y-value
    }
    p_val = p_tail_l +  r_tail_max_smaller
  }
  else{
    if(p_tail_r > a){
      # If the lowest tail value is higher than the significance level the test fails necessairly
      return(1)
    }
    if(2*p_tail_r < a){
      # If the highest tail value you add to the p_value is lower than half the null hypthesis is rejected
      return(0)
    }
    # Do the same thing but find maximum smaller left tail instead of right
    l_tail_max_smaller = 0
    y = 0
    sugg = l_tail_max_smaller
    while(sugg < p_tail_r + epsilon){
      l_tail_max_smaller = sugg # Accept suggestion
      l_add = dmodel(y, c, n_1, n_2) # Calculate new point mass to be added
      sugg = sugg + l_add # Propose new suggestion
      y = y + 1 # Take one higher y-value
    }
    p_val = p_tail_r +  l_tail_max_smaller
  }
  if(p_val > 1){ # If the distrbution is symmetric it will count the central event twice.
    return(1)
  }
  p_val
}

```


```{r}
p_val_d <- function(x, c, n_1, n_2) {
  exp_val = expected_val_model(c, n_1, n_2)
  W_x = abs(x - exp_val)
  
  p_val = 0
  S = sample_space(c)
  for(y in S){
    W_y = abs(y - exp_val)
    if(W_y < W_x){}
    else{
      p_val = p_val + dmodel(y, c, n_1, n_2)
    }
  }
  p_val
}

p_val_d(6, 10, 20, 14)
```

## Calculating power

```{r}

power_calc_fischer_null_hyp_true <- function(method, p_both, n_1, n_2, a){
  power = 0
  for(x in 0:n_1){
    for(y in 0:n_2){
      p_val = method(x, x+y, n_1, n_2)
      if(p_val < a){
        power = power + dbinom(x, n_1, p_both) * dbinom(y, n_2, p_both)
      }
    }
  }
  power
}

power_calc_fischer_null_hyp_true(p_val_c_power, 0.9, 10, 10, 0.05)

```

```{r}
n = 100
N = 100
P = (0:N)/N
b_double = NULL
b_point = NULL
b_tail = NULL
b_dist = NULL

for(p in P){
  # Calculate power
  power_double = power_calc_fischer_null_hyp_true(p_val_a, p, n, n + 40, .05)
  power_point = power_calc_fischer_null_hyp_true(p_val_b, p, n, n + 40, .05)
  power_tail = power_calc_fischer_null_hyp_true(p_val_c_power, p, n, n +40, .05)
  power_dist = power_calc_fischer_null_hyp_true(p_val_d, p, n, n +40, .05)
    
  # Add power to the list
  b_double = c(b_double, power_double)
  b_point = c(b_point, power_point)
  b_tail = c(b_tail, power_tail)
  b_dist = c(b_dist, power_dist)
}

df_power <- data.frame(P, b_double, b_point, b_tail, b_dist)
```

```{r}
ggplot(data = df_power)+
  geom_point(aes(x = P, y = b_dist), alpha = 0.8)+
  geom_point(aes(x = P, y = b_point), color = "red", alpha = 0.6)+
  geom_point(aes(x = P, y = b_tail), color = "green", alpha = 0.3)+
  geom_point(aes(x = P, y = b_double), color = "blue", alpha = 0.8)+
  labs(x = "*P*<sub>1</sub> = *P*<sub>2</sub>", y = "Type 1 Error", title = glue("*n*<sub>1</sub> = {n} / *n*<sub>2</sub> = {n +40}"))+
  theme(axis.title = element_markdown(), title = element_markdown())
```
# Testing for a cross-section with p_0 = 0.5 and a = 0.05
```{r}
power_calc_fischer_alt <- function(method, p_2, n_1, n_2, a, p_1 = .05){
  power = 0
  for(x in 0:n_1){
    for(y in 0:n_2){
      p_val = method(x, x+y, n_1, n_2)
      if(p_val < a){
        power = power + dbinom(x, n_1, p_1) * dbinom(y, n_2, p_2)
      }
    }
  }
  power
}

N = 100
n = 40
alpha = .05
P = (0:N)/N
b_double = NULL
b_point = NULL
b_tail = NULL
b_dist = NULL

for(p in P){
  # Calculate power
  power_double = power_calc_fischer_alt(p_val_a, p, n, n +10, alpha)
  power_point = power_calc_fischer_alt(p_val_b, p, n, n +10, alpha)
  power_tail = power_calc_fischer_alt(p_val_c_power, p, n, n +10, alpha)
  power_dist = power_calc_fischer_alt(p_val_d, p, n, n +10, alpha)
    
  # Add power to the list
  b_double = c(b_double, power_double)
  b_point = c(b_point, power_point)
  b_tail = c(b_tail, power_tail)
  b_dist = c(b_dist, power_dist)
}

df_power <- data.frame(P, b_double, b_point, b_tail, b_dist)
```

```{r}
colnames(df_power) <- c("P", "â€‹Double tail", "Point", "Tail", "Distance") 

df_power %>%
  pivot_longer(cols = -P, values_to = "Power", names_to = "Method") %>%
  ggplot()+
  geom_line(aes(x = P, y = Power, colour = Method, linetype = Method))+
  labs(x= "*P*<sub>2</sub>", title = "*P*<sub>1</sub> = 0.05, *n*<sub>1</sub> = 40 / *n*<sub>2</sub> = 50")+
  theme(axis.title = element_markdown(), title = element_markdown())
  
```

```{r}
my_array <- array(1:12, dim = c(3, 4))

# Convert the array to a data frame
my_df <- as.data.frame(my_array)

write.table(my_df, file = "my_array_test.csv", sep = ",", row.names = FALSE, col.names = TRUE)

my_df = NULL

my_array = NULL

my_df <- read.table("my_array_test.csv", sep = ",", header = TRUE)

# Convert the data frame back to an array
my_array <- as.matrix(my_df)
```

```{r}
# Define a function
my_function <- function(x) {
  return(x * 2)
}

# Get the name of the function
function_name <- deparse(substitute(my_function))

# Print the function name
print(function_name)  # Output: "my_function"
```


```{r}
power_surface <- function(method, n_1, n_2, N, a){
  power_mat <- matrix(0, N+1, N+1)
  for(i in 0:N){
    p_1 = i/N
    for(j in 0:N){
      p_2 = j/N
      power_ij = power_calc_fischer_alt(method, p_2, n_1, n_2, a, p_1)
      power_mat[i, j] <- power_ij
    }
  }
  power_mat
}

n_1 = 40
n_2 = 50
N = 20
alpha = .05

methods = list(double_tail = p_val_a, point = p_val_b, tail = p_val_c_power, distance = p_val_d)

for(i in 1:4){
  m = methods[[i]]
  power_surf = power_surface(m, n_1, n_2, N, alpha)
  print(power_surf)
  method_name = names(methods)[i]
  filename = glue("power_surf_{method_name}_model_{n_1}_{n_2}_stepnum_{N}_sign_{alpha}.csv")
  print(filename)
  write.table(power_surf, file = filename, sep = ",", row.names = FALSE, col.names = TRUE)
}

# power_surf_a <- power_surface(p_val_a, n_1, n_2, N, alpha)
# power_surf_b <- power_surface(p_val_b, n_1, n_2, N, alpha)
# power_surf_c <- power_surface(p_val_c_power, n_1, n_2, N, alpha)
# power_surf_d <- power_surface(p_val_d, n_1, n_2, N, alpha)

```

```{r}
write.table(my_df, file = "my_array.csv", sep = ",", row.names = FALSE, col.names = TRUE)

```


```{r}
make_heatmap<- function(df){
  melt_df = melt(df)
  colnames(melt_df) <- c("x", "y", "power_diff")
  plot <- ggplot(melt_df, aes(x = x/sqrt(length(x)), y = y/sqrt(length(y)), fill = power_diff))+
    geom_tile()+
    scale_fill_gradient(low = "green", mid = "white", high = "red", limits = c(-.1, .1))+
    labs(x = "P_0", y = "True p")+
    theme_classic()
  return(plot)
}

plotList = list()

plotList[[1]] = make_heatmap(power_surf_a - power_surf_a)
plotList[[2]] = NULL
plotList[[3]] = NULL
plotList[[4]] = NULL
plotList[[5]] = make_heatmap(power_surf_a - power_surf_b)
plotList[[6]] = make_heatmap(power_surf_b - power_surf_b) 
plotList[[7]] = NULL
plotList[[8]] = NULL
plotList[[9]] = make_heatmap(power_surf_a - power_surf_c)
plotList[[10]] = make_heatmap(power_surf_b - power_surf_c)
plotList[[11]] = make_heatmap(power_surf_c - power_surf_c) 
plotList[[12]] = NULL
plotList[[13]] = make_heatmap(power_surf_a - power_surf_d)
plotList[[14]] = make_heatmap(power_surf_b - power_surf_d)
plotList[[15]] = make_heatmap(power_surf_c - power_surf_d)
plotList[[16]] = make_heatmap(power_surf_d - power_surf_d)

plotList[[5]]

ggmatrix(plotList, 4, 4,
         xAxisLabels = c("Double tail", "Point", "Tail", "Distance"),
         yAxisLabels = c("Double tail", "Point", "Tail", "Distance"), 
         legend = grab_legend(plotList[[1]]))
```


```{r}

plot_power <- plot_ly(z = power_surf_a, type = "surface")
plot_power <- plot_power %>% add_surface(z = power_surf_b, colorscale = list(c(0, 1), c("pink", "red")))
plot_power <- plot_power %>% add_surface(z = power_surf_c, colorscale = list(c(0, 1), c("pink", "red")))
#plot_power <- plot_power %>% add_surface(z = power_surf_d, colorscale = list(c(0, 1), c("tan", "blue")))
plot_power
```

